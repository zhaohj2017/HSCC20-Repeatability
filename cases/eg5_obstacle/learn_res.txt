-----------------------first try boundary 0.05 and other tol=0 ------------------------------------------------

restart: 0 epoch: 3 batch: 4095 batch_loss: 0.0 batch_gradient: 1.7162641905355285 epoch_loss: 0.0 

The last epoch: 3
Success! The nn model is:

tensor([[ 0.5764,  0.6653, -1.1006],
        [ 0.7260, -0.3099,  1.0679],
        [-0.2637,  0.4489, -0.1036],
        [-0.0116,  1.5060, -0.4290],
        [-0.6049,  1.6146, -0.0157],
        [ 0.8613,  0.2861,  0.0070],
        [ 0.6895,  0.1697,  0.8267],
        [-0.3256,  0.3243, -0.0878],
        [ 0.0733, -1.0559, -0.4784],
        [-0.4800, -0.5353, -0.4793],
        [-1.1722, -0.3479, -0.7045],
        [-0.5254, -0.1889, -0.8292],
        [ 0.2753,  1.7501,  0.0818],
        [ 0.6872, -0.4590,  0.1750],
        [-0.2351,  0.6490,  0.1533],
        [ 0.6820,  0.8598,  0.1321],
        [ 0.0475, -0.7000,  0.5370],
        [-0.6049,  0.2438,  0.2494],
        [ 0.6683, -0.3380,  0.0125],
        [-0.0303, -0.0640,  0.2352]])
tensor([-0.7368,  0.0823,  0.1994, -0.9020,  0.6531,  0.6157, -0.0345, -0.2468,
        -0.6082,  0.7043, -0.6457,  0.5366, -0.0515,  0.1072,  0.5038, -0.2576,
         0.3242, -0.7319,  0.9047, -0.5395])
tensor([[ 0.4396,  0.0563,  0.0641,  0.4094, -0.1063,  0.4952,  0.2286, -0.5581,
         -0.4308, -0.4712,  0.0367, -0.0311, -0.8457, -0.3756, -0.1559, -0.8038,
          0.2921, -0.1149,  0.2736, -0.0217]])
tensor([0.3012])
restart: 0

Data generation totally cost: 0.42723965644836426
Training totally cost: 263.14763283729553


---------------------------try 10 neurons first try 1 boundary = 0.05 ---------------------

restart: 0 epoch: 13 batch: 4095 batch_loss: 0.0 batch_gradient: 0.9829525416530376 epoch_loss: 0.0 

The last epoch: 13
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.1144,  1.6681,  0.1522],
        [-0.7222, -0.6632, -0.4191],
        [ 0.7848, -0.0031,  0.8383],
        [ 0.5715,  0.6661, -0.6818],
        [-0.2475,  0.2890, -0.0539],
        [-0.9811,  0.2417, -0.1420],
        [ 0.5086,  0.0344, -0.5901],
        [ 0.0473,  0.0440,  0.7151],
        [-0.6342,  1.1037,  0.2316]])
tensor([-0.5217,  0.1196, -0.0481, -1.3206, -0.0383, -0.6170,  0.1971,  0.2922,
         0.5524,  0.3236])
tensor([[-0.1039, -0.6973, -0.7295, -0.4210,  0.3549, -0.6276, -0.0382,  0.3477,
          0.6037, -0.3809]])
tensor([0.1087])
restart: 0

Data generation totally cost: 0.41481518745422363
Training totally cost: 890.1048560142517

------------------------------fine tune 2 from 1----------------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.05
TOL_BOUNDARY = 0.05
TOL_LIE = 0.005
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 14 batch: 4095 batch_loss: 0.0 batch_gradient: 1.2450906862093136 epoch_loss: 0.0 

The last epoch: 14
Success! The nn model is:

tensor([[-1.5389e-02,  1.2070e-01,  7.2088e-02],
        [ 1.1452e-01,  1.6141e+00,  2.0813e-01],
        [-7.8482e-01, -7.7080e-01, -4.3501e-01],
        [ 8.5986e-01,  3.1312e-03,  8.3307e-01],
        [ 6.6239e-01,  5.5863e-01, -7.4232e-01],
        [-2.4754e-01,  2.8901e-01, -5.3907e-02],
        [-9.8115e-01,  2.4744e-01, -1.4229e-01],
        [ 4.8742e-01,  4.9122e-02, -5.4398e-01],
        [ 4.4944e-02, -6.8061e-04,  7.6569e-01],
        [-6.4929e-01,  1.0878e+00,  2.1189e-01]])
tensor([-0.5217,  0.2254, -0.0466, -1.3098,  0.0146, -0.6170,  0.1413,  0.3265,
         0.5655,  0.3242])
tensor([[-0.1039, -0.5481, -0.8192, -0.4962,  0.4450, -0.6276, -0.0818,  0.3235,
          0.6199, -0.3864]])
tensor([0.1897])
restart: 0

----------------------------fine tune 3 from 2--------------------------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.05
TOL_BOUNDARY = 0.05
TOL_LIE = 0.01
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 8 batch: 4095 batch_loss: 0.0 batch_gradient: 1.2844207783454658 epoch_loss: 0.0 

The last epoch: 8
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.1198,  1.6115,  0.2094],
        [-0.7855, -0.7735, -0.4343],
        [ 0.8644,  0.0045,  0.8338],
        [ 0.6634,  0.5598, -0.7391],
        [-0.2475,  0.2890, -0.0539],
        [-0.9808,  0.2486, -0.1439],
        [ 0.4868,  0.0481, -0.5438],
        [ 0.0390, -0.0047,  0.7667],
        [-0.6536,  1.0876,  0.2059]])
tensor([-0.5217,  0.2235, -0.0466, -1.3074,  0.0112, -0.6170,  0.1376,  0.3278,
         0.5678,  0.3233])
tensor([[-0.1039, -0.5426, -0.8218, -0.4989,  0.4435, -0.6276, -0.0787,  0.3238,
          0.6233, -0.3905]])
tensor([0.1897])
restart: 0

Data generation totally cost: 0.3994457721710205
Training totally cost: 579.5088739395142

-----------------------------fine tune 4 from 3 --------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.07
TOL_LIE = 0.01
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 9 batch: 4095 batch_loss: 0.0 batch_gradient: 0.743454406265153 epoch_loss: 0.0 

The last epoch: 9
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.0933,  1.5794,  0.2318],
        [-0.7920, -0.8444, -0.4556],
        [ 0.8999,  0.0093,  0.8378],
        [ 0.6293,  0.6378, -0.7240],
        [-0.2475,  0.2890, -0.0539],
        [-0.9789,  0.2524, -0.1467],
        [ 0.4605,  0.0703, -0.5280],
        [ 0.0421, -0.0319,  0.7746],
        [-0.6713,  1.0643,  0.2021]])
tensor([-0.5217,  0.3344, -0.0973, -1.2996,  0.0049, -0.6170,  0.1013,  0.3411,
         0.5977,  0.3652])
tensor([[-0.1039, -0.4891, -0.8679, -0.5462,  0.4588, -0.6276, -0.0578,  0.2997,
          0.6321, -0.4010]])
tensor([0.2357])
restart: 0

Data generation totally cost: 0.41417527198791504
Training totally cost: 700.4150166511536

---------------------------fine tune 5 from 4---------------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.07
TOL_LIE = 0.02
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 3 batch: 4095 batch_loss: 0.0 batch_gradient: 1.5231864696382647 epoch_loss: 0.0 

The last epoch: 3
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.0927,  1.5795,  0.2339],
        [-0.7869, -0.8473, -0.4530],
        [ 0.9013,  0.0098,  0.8375],
        [ 0.6324,  0.6343, -0.7253],
        [-0.2475,  0.2890, -0.0539],
        [-0.9790,  0.2531, -0.1471],
        [ 0.4595,  0.0665, -0.5275],
        [ 0.0382, -0.0309,  0.7787],
        [-0.6722,  1.0620,  0.2005]])
tensor([-0.5217,  0.3370, -0.1031, -1.2988,  0.0080, -0.6170,  0.0995,  0.3436,
         0.5934,  0.3739])
tensor([[-0.1039, -0.4929, -0.8655, -0.5462,  0.4608, -0.6276, -0.0611,  0.2996,
          0.6328, -0.4049]])
tensor([0.2357])
restart: 0

Data generation totally cost: 0.5244150161743164
Training totally cost: 295.4719920158386

----------------------------fine tune 6 from 5----------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.07
TOL_LIE = 0.05
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 10 batch: 4095 batch_loss: 0.0 batch_gradient: 0.6867665211579841 epoch_loss: 0.0 

The last epoch: 10
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.0984,  1.5878,  0.3112],
        [-0.8754, -0.9354, -0.4599],
        [ 0.9569,  0.0497,  0.8574],
        [ 0.2357,  1.2349, -0.7059],
        [-0.2475,  0.2890, -0.0539],
        [-0.9858,  0.2861, -0.1961],
        [ 0.5054,  0.0788, -0.4683],
        [ 0.0609, -0.0296,  0.8942],
        [-0.6287,  1.1003,  0.2419]])
tensor([-0.5217,  0.3446, -0.2270, -1.2498, -0.3020, -0.6170, -0.0822,  0.3333,
         0.4693,  0.2740])
tensor([[-0.1039, -0.5462, -0.8951, -0.5513,  0.5464, -0.6276, -0.2913,  0.3115,
          0.6663, -0.4186]])
tensor([0.2967])
restart: 0

Data generation totally cost: 0.45645618438720703
Training totally cost: 911.5045869350433


----------------------------fine tune 7 from 6----------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.07
TOL_LIE = 0.1
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 4 batch: 4094 batch_loss: 0.0 batch_gradient: 1.9176805039084295 epoch_loss: 0.0 

restart: 0 epoch: 4 batch: 4095 batch_loss: 0.0 batch_gradient: 1.3362152322171195 epoch_loss: 0.0 

The last epoch: 4
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.1181,  1.5968,  0.2376],
        [-0.9665, -0.9911, -0.3844],
        [ 0.9736,  0.0493,  0.8310],
        [ 0.2517,  1.2178, -0.7634],
        [-0.2475,  0.2890, -0.0539],
        [-0.9782,  0.2904, -0.3130],
        [ 0.4117,  0.4250, -0.5352],
        [ 0.1115, -0.0930,  0.8754],
        [-0.6062,  1.1108,  0.1716]])
tensor([-0.5217,  0.3999, -0.3085, -1.2551, -0.2787, -0.6170, -0.0943,  0.1667,
         0.5328,  0.3082])
tensor([[-0.1039, -0.5689, -0.9872, -0.5511,  0.5728, -0.6276, -0.3314,  0.2852,
          0.6613, -0.4089]])
tensor([0.3367])
restart: 0

Data generation totally cost: 0.6906588077545166
Training totally cost: 385.8842179775238


----------------------------fine tune 8 from 7----------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.09
TOL_LIE = 0.1
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 2 batch: 4095 batch_loss: 0.0 batch_gradient: 1.8576640336119021 epoch_loss: 0.0 

The last epoch: 2
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.1164,  1.5959,  0.2364],
        [-0.9687, -0.9898, -0.3798],
        [ 0.9736,  0.0493,  0.8310],
        [ 0.2535,  1.2183, -0.7589],
        [-0.2475,  0.2890, -0.0539],
        [-0.9791,  0.2920, -0.3111],
        [ 0.4119,  0.4244, -0.5364],
        [ 0.1114, -0.0917,  0.8744],
        [-0.6073,  1.1094,  0.1655]])
tensor([-0.5217,  0.4031, -0.3115, -1.2551, -0.2837, -0.6170, -0.0966,  0.1682,
         0.5328,  0.3154])
tensor([[-0.1039, -0.5680, -0.9871, -0.5511,  0.5714, -0.6276, -0.3343,  0.2878,
          0.6598, -0.4102]])
tensor([0.3407])
restart: 0

Data generation totally cost: 0.46302056312561035
Training totally cost: 220.72172117233276


----------------------------fine tune 9 from 8---------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.09
TOL_LIE = 0.12
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 19 batch: 4095 batch_loss: 0.0 batch_gradient: 0.9193125114656363 epoch_loss: 0.0 

The last epoch: 19
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.0987,  1.5945,  0.2477],
        [-0.9643, -0.9940, -0.4086],
        [ 0.9735,  0.0495,  0.8310],
        [ 0.2623,  1.2152, -0.7574],
        [-0.2475,  0.2890, -0.0539],
        [-0.9867,  0.3014, -0.2986],
        [ 0.3901,  0.4503, -0.5366],
        [ 0.0941, -0.0781,  0.8652],
        [-0.6157,  1.1156,  0.1668]])
tensor([-0.5217,  0.4100, -0.3186, -1.2552, -0.2823, -0.6170, -0.1079,  0.1725,
         0.5559,  0.3151])
tensor([[-0.1039, -0.5741, -0.9996, -0.5511,  0.5676, -0.6276, -0.3589,  0.2995,
          0.6654, -0.4413]])
tensor([0.3417])
restart: 0

Data generation totally cost: 0.4581272602081299
Training totally cost: 1365.908212184906


----------------------------fine tune 10 from 9---------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.10
TOL_LIE = 0.12
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1


restart: 0 epoch: 7 batch: 4095 batch_loss: 0.0 batch_gradient: 1.5300220286121011 epoch_loss: 0.0 

The last epoch: 7
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.0930,  1.5937,  0.2488],
        [-0.9583, -0.9978, -0.4155],
        [ 0.9735,  0.0496,  0.8310],
        [ 0.2649,  1.2143, -0.7573],
        [-0.2475,  0.2890, -0.0539],
        [-0.9884,  0.3030, -0.2955],
        [ 0.3805,  0.4626, -0.5357],
        [ 0.0887, -0.0738,  0.8630],
        [-0.6181,  1.1160,  0.1630]])
tensor([-0.5217,  0.4142, -0.3276, -1.2552, -0.2814, -0.6170, -0.1108,  0.1716,
         0.5623,  0.3191])
tensor([[-0.1039, -0.5752, -1.0037, -0.5511,  0.5665, -0.6276, -0.3642,  0.3043,
          0.6676, -0.4476]])
tensor([0.3407])
restart: 0

Data generation totally cost: 0.3787193298339844
Training totally cost: 593.6790995597839

----------------------------fine tune 11 from 10---------------------------------
TOL_INIT = 0.05
TOL_SAFE = 0.07
TOL_BOUNDARY = 0.10
TOL_LIE = 0.15
TOL_NORM_LIE = 0.0
WEIGHT_LIE = 1
WEIGHT_NORM_LIE = 0

DECAY_LIE = 1
DECAY_INIT = 1
DECAY_UNSAFE = 1

restart: 0 epoch: 28 batch: 4094 batch_loss: 0.0 batch_gradient: 1.4573975600713638 epoch_loss: 0.0 

restart: 0 epoch: 28 batch: 4095 batch_loss: 0.0 batch_gradient: 1.8920998420353956 epoch_loss: 0.0 

The last epoch: 28
Success! The nn model is:

tensor([[-0.0154,  0.1207,  0.0721],
        [ 0.0855,  1.5956,  0.2696],
        [-0.9973, -0.9949, -0.4558],
        [ 0.9997,  0.0550,  0.8147],
        [ 0.2742,  1.2206, -0.7480],
        [-0.2475,  0.2890, -0.0539],
        [-1.0115,  0.3225, -0.2749],
        [ 0.3411,  0.4940, -0.5462],
        [ 0.0259, -0.0483,  0.8617],
        [-0.6153,  1.1355,  0.1721]])
tensor([-0.5217,  0.4236, -0.3542, -1.2463, -0.2801, -0.6170, -0.1140,  0.2003,
         0.5919,  0.3090])
tensor([[-0.1039, -0.6013, -1.0555, -0.5538,  0.5712, -0.6276, -0.4307,  0.3405,
          0.6893, -0.4951]])
tensor([0.3317])
restart: 0

Data generation totally cost: 0.5558803081512451
Training totally cost: 1986.38813996315

