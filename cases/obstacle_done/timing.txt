###############timing is done on the first try parameters######################

0
Initialize parameters!

Half parameters!
The last epoch: 31
Success! The nn model is:

tensor([[-0.0432,  1.6892,  0.1908],
        [ 0.5422,  0.6599,  0.2962],
        [ 0.6384,  0.9368,  0.6299],
        [-0.4289, -0.3152, -0.0843],
        [-0.5619, -0.3925, -0.3466],
        [ 0.7452,  0.4066,  0.6741],
        [ 0.0213, -0.1601,  0.6420],
        [-0.3651,  0.1059,  0.7312],
        [ 0.1474,  0.1497, -0.2007],
        [-0.8259,  0.6012,  0.1179]])
tensor([-0.1616,  0.8618, -1.1795, -0.9539,  0.0285,  0.3629, -0.6653, -0.1932,
        -0.0435,  0.1203])
tensor([[-0.9116,  0.1712, -0.8448, -0.2741, -0.1583,  0.1864,  0.4703,  0.3934,
          0.2268, -0.4639]])
tensor([0.0556])
restart: 0

Data generation totally cost: 0.3847222328186035
Training totally cost: 1527.771234035492
1
Initialize parameters!

Half parameters!
Initialize parameters!

The last epoch: 52
Success! The nn model is:

tensor([[ 0.8027,  0.3938,  1.4014],
        [-0.5675, -1.8527, -1.1673],
        [ 1.2625,  1.4732,  0.5635],
        [-1.3318,  1.8853, -0.2280],
        [-1.0860,  1.8465,  0.4748],
        [-1.6203,  0.9592,  0.4651],
        [ 1.0185, -0.0791, -0.6057],
        [ 0.3778, -0.0739, -1.2943],
        [-0.2530,  1.6460, -0.7798],
        [-0.1935, -0.7547,  0.1971]])
tensor([ 1.1748, -1.2794, -0.5035, -0.6232,  1.3515,  0.1288,  0.4088, -0.6930,
        -2.8198,  1.0793])
tensor([[ 0.6999, -0.8018, -1.1871, -0.6104, -0.2908, -0.0726,  0.6779,  0.1729,
          0.4912,  0.0447]])
tensor([-0.1291])
restart: 1

Data generation totally cost: 0.36265015602111816
Training totally cost: 7254.641105413437
2
Initialize parameters!

The last epoch: 22
Success! The nn model is:

tensor([[ 0.3674,  1.8955, -1.9377],
        [-0.1281,  2.0545,  0.2546],
        [ 1.2526, -0.7767, -0.5935],
        [ 0.2316, -1.5438, -0.3891],
        [-0.2550, -0.1051, -0.0602],
        [-1.1568, -0.8776, -1.3482],
        [-0.4280, -0.4970,  0.5504],
        [ 0.9514,  0.2518, -1.3166],
        [ 0.6098, -0.7967,  0.4033],
        [-1.5893, -0.9108, -0.4945]])
tensor([-1.2166,  0.7945, -1.9346, -1.3718,  0.6893, -1.6531, -0.0556, -1.5353,
        -1.7279,  0.4086])
tensor([[ 0.4720, -0.5254,  0.3070, -0.3782,  0.1207,  0.0117,  0.3920,  0.7658,
          1.1317, -0.5936]])
tensor([0.8898])
restart: 0

Data generation totally cost: 0.3662440776824951
Training totally cost: 1083.9047446250916
3
Initialize parameters!

The last epoch: 9
Success! The nn model is:

tensor([[ 0.8907,  1.3789,  0.1733],
        [ 0.4411,  0.1319,  1.2039],
        [-0.8716, -1.5853, -0.7052],
        [-0.8943,  1.2164, -0.6174],
        [ 0.3865,  0.9819, -1.3244],
        [ 0.2599,  1.8808,  0.1925],
        [ 0.0124, -0.1935,  0.7945],
        [-0.7272,  1.9496, -0.5814],
        [-0.0453,  1.2272,  0.3183],
        [ 0.7301,  0.2732,  0.2474]])
tensor([-1.1221, -1.3608,  0.1073, -1.6307, -0.6595,  1.0764,  0.1015, -0.3880,
         1.1477,  1.4584])
tensor([[-0.7749,  0.2149, -0.5589, -0.1055,  0.5085, -0.3631,  0.4216, -0.5097,
         -0.2537,  0.5171]])
tensor([0.4215])
restart: 0

Data generation totally cost: 0.3683912754058838
Training totally cost: 487.04056692123413
4
Initialize parameters!

Half parameters!
Initialize parameters!

Half parameters!
The last epoch: 15
Success! The nn model is:

tensor([[-0.2082, -1.0067, -0.5388],
        [-1.7785, -0.1790, -0.7720],
        [-0.3390,  0.0459,  0.1802],
        [ 0.8590, -1.1027,  0.4111],
        [-0.0391,  0.0310, -0.0447],
        [-0.9811,  0.2766, -0.4580],
        [ 0.3019,  0.8094, -0.7277],
        [ 0.2069,  0.7032, -0.4690],
        [-0.7278, -0.3900, -0.4537],
        [ 0.0426,  1.1548, -0.0235]])
tensor([-1.0301, -2.3246, -1.3411, -2.2473,  0.3252, -0.3098, -0.3458, -1.6798,
         0.1495,  0.1930])
tensor([[-0.2533, -0.3156,  0.4292,  0.0900,  0.0113, -0.2213,  0.3421,  0.2580,
         -0.2216, -0.3387]])
tensor([0.2257])
restart: 1

Data generation totally cost: 0.3743119239807129
Training totally cost: 5473.0353055000305
